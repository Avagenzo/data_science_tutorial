{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path.home() / \"data\" / \"tmp\"\n",
    "reuters_dir = data_root / \"reuters21578\"\n",
    "reuters_corpus_path = reuters_dir / \"corpus.pkl\"\n",
    "reuters = pickle.load(open(reuters_corpus_path, \"rb\"))\n",
    "top_ten_ids, top_ten_names = reuters.top_n(n=10)\n",
    "\n",
    "cache_dir = reuters_dir / \"cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, top_ten_ids, train_labels, test_labels = reuters.build_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modapte</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>dateline</th>\n",
       "      <th>body</th>\n",
       "      <th>newid</th>\n",
       "      <th>wd_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>interest</td>\n",
       "      <td>0</td>\n",
       "      <td>1987-03-11 18:14:49</td>\n",
       "      <td>U.S. ECONOMIC DATA KEY TO DEBT FUTURES OUTLOOK</td>\n",
       "      <td>CHICAGO, March 11 -</td>\n",
       "      <td>U.S. economic data this week could be\\nthe key...</td>\n",
       "      <td>4005</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>earn</td>\n",
       "      <td>3</td>\n",
       "      <td>1987-03-11 18:36:05</td>\n",
       "      <td>BANK OF BRITISH COLUMBIA 1ST QTR JAN 31 NET</td>\n",
       "      <td>VANCOUVER, British Columbia, March 11 -\\n</td>\n",
       "      <td>Oper shr loss two cts vs profit three cts\\n   ...</td>\n",
       "      <td>4012</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>earn</td>\n",
       "      <td>3</td>\n",
       "      <td>1987-03-11 18:38:02</td>\n",
       "      <td>RESTAURANT ASSOCIATES INC &lt;RA&gt; 4TH QTR JAN 3</td>\n",
       "      <td>NEW YORK, March 11 -\\n</td>\n",
       "      <td>Shr 25 cts vs 36 cts\\n    Net 1.4 mln vs 1.4 m...</td>\n",
       "      <td>4014</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>earn</td>\n",
       "      <td>3</td>\n",
       "      <td>1987-03-11 18:41:59</td>\n",
       "      <td>MICHIGAN GENERAL CORP &lt;MGL&gt; 4TH QTR</td>\n",
       "      <td>SADDLE BROOK, N.J., March 11 -\\n</td>\n",
       "      <td>Shr loss 1.02 dlrs vs 1.01 dlr\\n    Net loss 1...</td>\n",
       "      <td>4015</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>crude</td>\n",
       "      <td>4</td>\n",
       "      <td>1987-03-11 18:45:36</td>\n",
       "      <td>USX &lt;X&gt; PROVED OIL, GAS RESERVES FALL IN 1986</td>\n",
       "      <td>NEW YORK, March 11 -</td>\n",
       "      <td>USX Corp said proved reserves of oil\\nand natu...</td>\n",
       "      <td>4016</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modapte  category  label                date  \\\n",
       "0   train  interest      0 1987-03-11 18:14:49   \n",
       "1   train      earn      3 1987-03-11 18:36:05   \n",
       "2   train      earn      3 1987-03-11 18:38:02   \n",
       "3   train      earn      3 1987-03-11 18:41:59   \n",
       "4   train     crude      4 1987-03-11 18:45:36   \n",
       "\n",
       "                                            title  \\\n",
       "0  U.S. ECONOMIC DATA KEY TO DEBT FUTURES OUTLOOK   \n",
       "1     BANK OF BRITISH COLUMBIA 1ST QTR JAN 31 NET   \n",
       "2    RESTAURANT ASSOCIATES INC <RA> 4TH QTR JAN 3   \n",
       "3             MICHIGAN GENERAL CORP <MGL> 4TH QTR   \n",
       "4   USX <X> PROVED OIL, GAS RESERVES FALL IN 1986   \n",
       "\n",
       "                                            dateline  \\\n",
       "0                               CHICAGO, March 11 -    \n",
       "1      VANCOUVER, British Columbia, March 11 -\\n       \n",
       "2                         NEW YORK, March 11 -\\n       \n",
       "3               SADDLE BROOK, N.J., March 11 -\\n       \n",
       "4                              NEW YORK, March 11 -    \n",
       "\n",
       "                                                body newid    wd_name  \n",
       "0  U.S. economic data this week could be\\nthe key...  4005  Wednesday  \n",
       "1  Oper shr loss two cts vs profit three cts\\n   ...  4012  Wednesday  \n",
       "2  Shr 25 cts vs 36 cts\\n    Net 1.4 mln vs 1.4 m...  4014  Wednesday  \n",
       "3  Shr loss 1.02 dlrs vs 1.01 dlr\\n    Net loss 1...  4015  Wednesday  \n",
       "4  USX Corp said proved reserves of oil\\nand natu...  4016  Wednesday  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build feature extraction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_tutorial.transformers import TextFromColumns, TextStats, ColumnSelector, TextFromColumns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.query(\"modapte == 'train'\")\n",
    "df_test = df.query(\"modapte == 'test'\")\n",
    "y_train = df_train.label.values\n",
    "y_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(memory=str(cache_dir), steps=[\n",
    "    (\"union\", FeatureUnion(transformer_list=[\n",
    "        (\"title_stats\", Pipeline([\n",
    "            (\"column\", ColumnSelector(\"title\")),\n",
    "            (\"stats\", TextStats()),\n",
    "            (\"scaled\", StandardScaler()),\n",
    "        ])),\n",
    "        (\"body_stats\", Pipeline([\n",
    "            (\"column\", ColumnSelector(\"body\")),\n",
    "            (\"stats\", TextStats()),\n",
    "            (\"scaled\", StandardScaler()),\n",
    "        ])),\n",
    "        (\"combined_text\", Pipeline([\n",
    "            (\"column\", TextFromColumns2()),\n",
    "            #(\"tfidf\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(1, 5))),\n",
    "            (\"tfidf\", TfidfVectorizer()),\n",
    "            (\"best\", TruncatedSVD(n_components=300, random_state=2018))\n",
    "        ])),\n",
    "\n",
    "    ])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 1.49 s, total: 19.5 s\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = pipeline.fit_transform(df_train)\n",
    "X_test = pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "    \n",
    "    model.add(Dense(units=num_classes, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_model(3, 32, 0.2, X_train.shape[1:], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "7770/7770 [==============================] - 0s 51us/step - loss: 0.8793 - acc: 0.7663\n",
      "Epoch 2/70\n",
      "7770/7770 [==============================] - 0s 48us/step - loss: 0.8704 - acc: 0.7644\n",
      "Epoch 3/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.8440 - acc: 0.7687\n",
      "Epoch 4/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.8185 - acc: 0.7793\n",
      "Epoch 5/70\n",
      "7770/7770 [==============================] - 0s 63us/step - loss: 0.8116 - acc: 0.7788\n",
      "Epoch 6/70\n",
      "7770/7770 [==============================] - 1s 71us/step - loss: 0.7795 - acc: 0.7855\n",
      "Epoch 7/70\n",
      "7770/7770 [==============================] - 1s 72us/step - loss: 0.7617 - acc: 0.7909\n",
      "Epoch 8/70\n",
      "7770/7770 [==============================] - 0s 52us/step - loss: 0.7623 - acc: 0.7900\n",
      "Epoch 9/70\n",
      "7770/7770 [==============================] - 0s 53us/step - loss: 0.7491 - acc: 0.7929\n",
      "Epoch 10/70\n",
      "7770/7770 [==============================] - 0s 51us/step - loss: 0.7423 - acc: 0.7950\n",
      "Epoch 11/70\n",
      "7770/7770 [==============================] - 0s 51us/step - loss: 0.7401 - acc: 0.7916\n",
      "Epoch 12/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.7269 - acc: 0.7946\n",
      "Epoch 13/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.7154 - acc: 0.8018\n",
      "Epoch 14/70\n",
      "7770/7770 [==============================] - 0s 51us/step - loss: 0.6947 - acc: 0.8039\n",
      "Epoch 15/70\n",
      "7770/7770 [==============================] - 0s 55us/step - loss: 0.6871 - acc: 0.8073\n",
      "Epoch 16/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.6797 - acc: 0.8121\n",
      "Epoch 17/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.6696 - acc: 0.8099\n",
      "Epoch 18/70\n",
      "7770/7770 [==============================] - 0s 48us/step - loss: 0.6716 - acc: 0.8122\n",
      "Epoch 19/70\n",
      "7770/7770 [==============================] - 0s 48us/step - loss: 0.6614 - acc: 0.8211\n",
      "Epoch 20/70\n",
      "7770/7770 [==============================] - 0s 60us/step - loss: 0.6450 - acc: 0.8207\n",
      "Epoch 21/70\n",
      "7770/7770 [==============================] - 1s 67us/step - loss: 0.6483 - acc: 0.8170\n",
      "Epoch 22/70\n",
      "7770/7770 [==============================] - 0s 53us/step - loss: 0.6471 - acc: 0.8154\n",
      "Epoch 23/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.6261 - acc: 0.8214\n",
      "Epoch 24/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.6282 - acc: 0.8183\n",
      "Epoch 25/70\n",
      "7770/7770 [==============================] - 0s 48us/step - loss: 0.6240 - acc: 0.8230\n",
      "Epoch 26/70\n",
      "7770/7770 [==============================] - 0s 56us/step - loss: 0.6298 - acc: 0.8230\n",
      "Epoch 27/70\n",
      "7770/7770 [==============================] - 0s 51us/step - loss: 0.6221 - acc: 0.8221\n",
      "Epoch 28/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.6052 - acc: 0.8290\n",
      "Epoch 29/70\n",
      "7770/7770 [==============================] - 0s 47us/step - loss: 0.6001 - acc: 0.8279\n",
      "Epoch 30/70\n",
      "7770/7770 [==============================] - 0s 47us/step - loss: 0.6040 - acc: 0.8292\n",
      "Epoch 31/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5924 - acc: 0.8272\n",
      "Epoch 32/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5968 - acc: 0.8265\n",
      "Epoch 33/70\n",
      "7770/7770 [==============================] - 0s 50us/step - loss: 0.5946 - acc: 0.8275\n",
      "Epoch 34/70\n",
      "7770/7770 [==============================] - 0s 52us/step - loss: 0.5821 - acc: 0.8318\n",
      "Epoch 35/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5861 - acc: 0.8318\n",
      "Epoch 36/70\n",
      "7770/7770 [==============================] - 0s 50us/step - loss: 0.5849 - acc: 0.8328\n",
      "Epoch 37/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5886 - acc: 0.8283\n",
      "Epoch 38/70\n",
      "7770/7770 [==============================] - 0s 50us/step - loss: 0.5781 - acc: 0.8340\n",
      "Epoch 39/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5619 - acc: 0.8342\n",
      "Epoch 40/70\n",
      "7770/7770 [==============================] - 0s 50us/step - loss: 0.5662 - acc: 0.8368\n",
      "Epoch 41/70\n",
      "7770/7770 [==============================] - 0s 51us/step - loss: 0.5612 - acc: 0.8360\n",
      "Epoch 42/70\n",
      "7770/7770 [==============================] - 0s 53us/step - loss: 0.5565 - acc: 0.8373\n",
      "Epoch 43/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5824 - acc: 0.8338\n",
      "Epoch 44/70\n",
      "7770/7770 [==============================] - 0s 48us/step - loss: 0.5574 - acc: 0.8382\n",
      "Epoch 45/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5527 - acc: 0.8387\n",
      "Epoch 46/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5522 - acc: 0.8359\n",
      "Epoch 47/70\n",
      "7770/7770 [==============================] - 0s 46us/step - loss: 0.5532 - acc: 0.8377\n",
      "Epoch 48/70\n",
      "7770/7770 [==============================] - 0s 48us/step - loss: 0.5388 - acc: 0.8457\n",
      "Epoch 49/70\n",
      "7770/7770 [==============================] - 0s 49us/step - loss: 0.5276 - acc: 0.8431\n",
      "Epoch 50/70\n",
      "7770/7770 [==============================] - 0s 52us/step - loss: 0.5362 - acc: 0.8457\n",
      "Epoch 51/70\n",
      "7770/7770 [==============================] - 0s 62us/step - loss: 0.5399 - acc: 0.8407\n",
      "Epoch 52/70\n",
      "7770/7770 [==============================] - 0s 51us/step - loss: 0.5389 - acc: 0.8395\n",
      "Epoch 53/70\n",
      "7770/7770 [==============================] - 0s 46us/step - loss: 0.5363 - acc: 0.8435\n",
      "Epoch 54/70\n",
      "7770/7770 [==============================] - 0s 46us/step - loss: 0.5321 - acc: 0.8413\n",
      "Epoch 55/70\n",
      "7770/7770 [==============================] - 0s 47us/step - loss: 0.5276 - acc: 0.8458\n",
      "Epoch 56/70\n",
      "7770/7770 [==============================] - 0s 55us/step - loss: 0.5144 - acc: 0.8465\n",
      "Epoch 57/70\n",
      "7770/7770 [==============================] - 0s 50us/step - loss: 0.5418 - acc: 0.8404\n",
      "Epoch 58/70\n",
      "7770/7770 [==============================] - 0s 45us/step - loss: 0.5271 - acc: 0.8413\n",
      "Epoch 59/70\n",
      "7770/7770 [==============================] - 0s 50us/step - loss: 0.5352 - acc: 0.8427\n",
      "Epoch 60/70\n",
      "7770/7770 [==============================] - 0s 45us/step - loss: 0.5188 - acc: 0.8448\n",
      "Epoch 61/70\n",
      "7770/7770 [==============================] - 0s 45us/step - loss: 0.5170 - acc: 0.8458\n",
      "Epoch 62/70\n",
      "7770/7770 [==============================] - 0s 43us/step - loss: 0.5124 - acc: 0.8457\n",
      "Epoch 63/70\n",
      "7770/7770 [==============================] - 0s 44us/step - loss: 0.5079 - acc: 0.8434\n",
      "Epoch 64/70\n",
      "7770/7770 [==============================] - 0s 44us/step - loss: 0.5172 - acc: 0.8453\n",
      "Epoch 65/70\n",
      "7770/7770 [==============================] - 0s 44us/step - loss: 0.4950 - acc: 0.8458\n",
      "Epoch 66/70\n",
      "7770/7770 [==============================] - 0s 44us/step - loss: 0.5327 - acc: 0.8458\n",
      "Epoch 67/70\n",
      "7770/7770 [==============================] - 0s 46us/step - loss: 0.5025 - acc: 0.8507\n",
      "Epoch 68/70\n",
      "7770/7770 [==============================] - 0s 45us/step - loss: 0.5082 - acc: 0.8499\n",
      "Epoch 69/70\n",
      "7770/7770 [==============================] - 0s 44us/step - loss: 0.5137 - acc: 0.8497\n",
      "Epoch 70/70\n",
      "7770/7770 [==============================] - 0s 44us/step - loss: 0.5072 - acc: 0.8432\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       earn      0.971     0.989     0.980      1087\n",
      "        acq      0.951     0.979     0.965       710\n",
      "   money-fx      0.681     0.855     0.758       145\n",
      "      grain      0.366     0.357     0.361        42\n",
      "      crude      0.725     0.902     0.804       164\n",
      "      trade      0.744     0.826     0.783       109\n",
      "   interest      0.804     0.701     0.749       117\n",
      "       ship      0.625     0.493     0.551        71\n",
      "      wheat      0.648     0.636     0.642        55\n",
      "       corn      0.405     0.667     0.504        45\n",
      "\n",
      "avg / total      0.879     0.915     0.895      2545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=top_ten_names, labels=top_ten_ids, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       earn      0.965     0.984     0.974      1087\n",
      "        acq      0.899     0.975     0.935       710\n",
      "   money-fx      0.661     0.821     0.732       145\n",
      "      grain      0.000     0.000     0.000        42\n",
      "      crude      0.714     0.823     0.765       164\n",
      "      trade      0.692     0.844     0.760       109\n",
      "   interest      0.780     0.726     0.752       117\n",
      "       ship      0.405     0.690     0.510        71\n",
      "      wheat      0.440     0.673     0.532        55\n",
      "       corn      0.340     0.711     0.460        45\n",
      "\n",
      "avg / total      0.839     0.908     0.869      2545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=top_ten_names, labels=top_ten_ids, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       earn      0.975     0.986     0.981      1087\n",
      "        acq      0.936     0.968     0.952       710\n",
      "   money-fx      0.738     0.834     0.783       145\n",
      "      grain      0.486     0.405     0.442        42\n",
      "      crude      0.765     0.872     0.815       164\n",
      "      trade      0.736     0.817     0.774       109\n",
      "   interest      0.816     0.795     0.805       117\n",
      "       ship      0.688     0.620     0.652        71\n",
      "      wheat      0.760     0.691     0.724        55\n",
      "       corn      0.706     0.800     0.750        45\n",
      "\n",
      "avg / total      0.894     0.919     0.906      2545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=top_ten_names, labels=top_ten_ids, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       earn      0.975     0.988     0.981      1087\n",
      "        acq      0.921     0.975     0.947       710\n",
      "   money-fx      0.753     0.800     0.776       145\n",
      "      grain      0.515     0.405     0.453        42\n",
      "      crude      0.761     0.835     0.797       164\n",
      "      trade      0.738     0.853     0.791       109\n",
      "   interest      0.767     0.786     0.776       117\n",
      "       ship      0.629     0.620     0.624        71\n",
      "      wheat      0.776     0.691     0.731        55\n",
      "       corn      0.630     0.756     0.687        45\n",
      "\n",
      "avg / total      0.886     0.918     0.901      2545\n",
      "\n",
      "CPU times: user 30.1 s, sys: 77.9 ms, total: 30.2 s\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=top_ten_names, labels=top_ten_ids, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Embedding(\n",
    "    input_dim=X_train.shape[1],\n",
    "    input_shape=X_train.shape[1:],\n",
    "    output_dim=32,\n",
    "    input_length=X_train[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_last_layer_units_and_activation(num_classes):\n",
    "    \"\"\"Gets the # units and activation function for the last network layer.\n",
    "\n",
    "    # Arguments\n",
    "        num_classes: int, number of classes.\n",
    "\n",
    "    # Returns\n",
    "        units, activation values.\n",
    "    \"\"\"\n",
    "    if num_classes == 2:\n",
    "        activation = 'sigmoid'\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        units = num_classes\n",
    "    return units, activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.layers import Embedding\n",
    "from tensorflow.python.keras.layers import SeparableConv1D\n",
    "from tensorflow.python.keras.layers import MaxPooling1D\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def sepcnn_model(blocks,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 embedding_dim,\n",
    "                 dropout_rate,\n",
    "                 pool_size,\n",
    "                 input_shape,\n",
    "                 num_classes,\n",
    "                 num_features,\n",
    "                 use_pretrained_embedding=False,\n",
    "                 is_embedding_trainable=False,\n",
    "                 embedding_matrix=None):\n",
    "    \"\"\"Creates an instance of a separable CNN model.\n",
    "\n",
    "    # Arguments\n",
    "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
    "        filters: int, output dimension of the layers.\n",
    "        kernel_size: int, length of the convolution window.\n",
    "        embedding_dim: int, dimension of the embedding vectors.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "        num_features: int, number of words (embedding input dimension).\n",
    "        use_pretrained_embedding: bool, true if pre-trained embedding is on.\n",
    "        is_embedding_trainable: bool, true if embedding layer is trainable.\n",
    "        embedding_matrix: dict, dictionary with embedding coefficients.\n",
    "\n",
    "    # Returns\n",
    "        A sepCNN model instance.\n",
    "    \"\"\"\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add embedding layer. If pre-trained embedding is used add weights to the\n",
    "    # embeddings layer and set trainable to input is_embedding_trainable flag.\n",
    "    if use_pretrained_embedding:\n",
    "        model.add(Embedding(input_dim=num_features,\n",
    "                            output_dim=embedding_dim,\n",
    "                            input_length=input_shape[0],\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=is_embedding_trainable))\n",
    "    else:\n",
    "        model.add(Embedding(input_dim=num_features,\n",
    "                            output_dim=embedding_dim,\n",
    "                            input_length=input_shape[0]))\n",
    "\n",
    "    for _ in range(blocks-1):\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "        model.add(SeparableConv1D(filters=filters,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  activation='relu',\n",
    "                                  bias_initializer='random_uniform',\n",
    "                                  depthwise_initializer='random_uniform',\n",
    "                                  padding='same'))\n",
    "        model.add(SeparableConv1D(filters=filters,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  activation='relu',\n",
    "                                  bias_initializer='random_uniform',\n",
    "                                  depthwise_initializer='random_uniform',\n",
    "                                  padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size))\n",
    "\n",
    "    model.add(SeparableConv1D(filters=filters * 2,\n",
    "                              kernel_size=kernel_size,\n",
    "                              activation='relu',\n",
    "                              bias_initializer='random_uniform',\n",
    "                              depthwise_initializer='random_uniform',\n",
    "                              padding='same'))\n",
    "    model.add(SeparableConv1D(filters=filters * 2,\n",
    "                              kernel_size=kernel_size,\n",
    "                              activation='relu',\n",
    "                              bias_initializer='random_uniform',\n",
    "                              depthwise_initializer='random_uniform',\n",
    "                              padding='same'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(op_units, activation=op_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextFromColumns2().transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing import text\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "TOP_K = 20000\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=TOP_K)\n",
    "\n",
    "train_text = TextFromColumns2().transform(df_train)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_text)\n",
    "test_text = TextFromColumns2().transform(df_test)\n",
    "X_test = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "max_length = len(max(X_train, key=len))\n",
    "if max_length > MAX_SEQUENCE_LENGTH:\n",
    "    max_length = MAX_SEQUENCE_LENGTH\n",
    "\n",
    "# Fix sequence length to max value. Sequences shorter than the length are\n",
    "# padded in the beginning and sequences longer are truncated\n",
    "# at the beginning.\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = min(len(tokenizer.word_index) + 1, TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7770, 500), (3019, 500), 20000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sepcnn_model(\n",
    "    blocks=2,\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    embedding_dim=200,\n",
    "    dropout_rate=0.2,\n",
    "    pool_size=3,\n",
    "    input_shape=X_train.shape[1:],\n",
    "    num_classes=75,\n",
    "    num_features=num_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7770 samples, validate on 3019 samples\n",
      "Epoch 1/10\n",
      "7770/7770 [==============================] - 25s 3ms/step - loss: 2.2530 - acc: 0.4356 - val_loss: 1.9861 - val_acc: 0.5250\n",
      "Epoch 2/10\n",
      "7770/7770 [==============================] - 26s 3ms/step - loss: 1.9402 - acc: 0.5483 - val_loss: 1.7536 - val_acc: 0.6048\n",
      "Epoch 3/10\n",
      "7770/7770 [==============================] - 26s 3ms/step - loss: 1.6488 - acc: 0.5996 - val_loss: 1.5019 - val_acc: 0.6482\n",
      "Epoch 4/10\n",
      "7770/7770 [==============================] - 27s 3ms/step - loss: 1.4457 - acc: 0.6368 - val_loss: 1.4372 - val_acc: 0.6625\n",
      "Epoch 5/10\n",
      "7770/7770 [==============================] - 29s 4ms/step - loss: 1.3414 - acc: 0.6615 - val_loss: 1.4308 - val_acc: 0.6671\n",
      "Epoch 6/10\n",
      "7770/7770 [==============================] - 40s 5ms/step - loss: 1.2307 - acc: 0.6746 - val_loss: 1.3247 - val_acc: 0.6847\n",
      "Epoch 7/10\n",
      "7770/7770 [==============================] - 45s 6ms/step - loss: 1.1968 - acc: 0.6792 - val_loss: 1.3421 - val_acc: 0.6860\n",
      "Epoch 8/10\n",
      "7770/7770 [==============================] - 40s 5ms/step - loss: 1.0839 - acc: 0.6999 - val_loss: 1.2096 - val_acc: 0.7244\n",
      "Epoch 9/10\n",
      "7040/7770 [==========================>...] - ETA: 2s - loss: 1.0075 - acc: 0.7210"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
